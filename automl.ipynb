{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/playground-series-s3e14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clonesize</th>\n",
       "      <th>honeybee</th>\n",
       "      <th>bumbles</th>\n",
       "      <th>andrena</th>\n",
       "      <th>osmia</th>\n",
       "      <th>MaxOfUpperTRange</th>\n",
       "      <th>MinOfUpperTRange</th>\n",
       "      <th>AverageOfUpperTRange</th>\n",
       "      <th>MaxOfLowerTRange</th>\n",
       "      <th>MinOfLowerTRange</th>\n",
       "      <th>AverageOfLowerTRange</th>\n",
       "      <th>RainingDays</th>\n",
       "      <th>AverageRainingDays</th>\n",
       "      <th>fruitset</th>\n",
       "      <th>fruitmass</th>\n",
       "      <th>seeds</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>69.7</td>\n",
       "      <td>42.1</td>\n",
       "      <td>58.2</td>\n",
       "      <td>50.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>41.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.425011</td>\n",
       "      <td>0.417545</td>\n",
       "      <td>32.460887</td>\n",
       "      <td>4476.81146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>69.7</td>\n",
       "      <td>42.1</td>\n",
       "      <td>58.2</td>\n",
       "      <td>50.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>41.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.444908</td>\n",
       "      <td>0.422051</td>\n",
       "      <td>33.858317</td>\n",
       "      <td>5548.12201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>86.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>62.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.552927</td>\n",
       "      <td>0.470853</td>\n",
       "      <td>38.341781</td>\n",
       "      <td>6869.77760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.50</td>\n",
       "      <td>77.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>64.7</td>\n",
       "      <td>55.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.565976</td>\n",
       "      <td>0.478137</td>\n",
       "      <td>39.467561</td>\n",
       "      <td>6880.77590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>77.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>64.7</td>\n",
       "      <td>55.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.579677</td>\n",
       "      <td>0.494165</td>\n",
       "      <td>40.484512</td>\n",
       "      <td>7479.93417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  clonesize  honeybee  bumbles  andrena  osmia  MaxOfUpperTRange  \\\n",
       "0   0       25.0      0.50     0.25     0.75   0.50              69.7   \n",
       "1   1       25.0      0.50     0.25     0.50   0.50              69.7   \n",
       "2   2       12.5      0.25     0.25     0.63   0.63              86.0   \n",
       "3   3       12.5      0.25     0.25     0.63   0.50              77.4   \n",
       "4   4       25.0      0.50     0.25     0.63   0.63              77.4   \n",
       "\n",
       "   MinOfUpperTRange  AverageOfUpperTRange  MaxOfLowerTRange  MinOfLowerTRange  \\\n",
       "0              42.1                  58.2              50.2              24.3   \n",
       "1              42.1                  58.2              50.2              24.3   \n",
       "2              52.0                  71.9              62.0              30.0   \n",
       "3              46.8                  64.7              55.8              27.0   \n",
       "4              46.8                  64.7              55.8              27.0   \n",
       "\n",
       "   AverageOfLowerTRange  RainingDays  AverageRainingDays  fruitset  fruitmass  \\\n",
       "0                  41.2         24.0                0.39  0.425011   0.417545   \n",
       "1                  41.2         24.0                0.39  0.444908   0.422051   \n",
       "2                  50.8         24.0                0.39  0.552927   0.470853   \n",
       "3                  45.8         24.0                0.39  0.565976   0.478137   \n",
       "4                  45.8         24.0                0.39  0.579677   0.494165   \n",
       "\n",
       "       seeds       yield  \n",
       "0  32.460887  4476.81146  \n",
       "1  33.858317  5548.12201  \n",
       "2  38.341781  6869.77760  \n",
       "3  39.467561  6880.77590  \n",
       "4  40.484512  7479.93417  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"yield\", axis=1)\n",
    "y = data[\"yield\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 12-02 22:35:36] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 12-02 22:35:36] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 12-02 22:35:36] {1788} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl.logger: 12-02 22:35:36] {1811} WARNING - No search budget is provided via time_budget or max_iter. Training only one model per estimator. Zero-shot AutoML is used for certain tasks and estimators. To tune hyperparameters for each estimator, please provide budget either via time_budget or max_iter.\n",
      "[flaml.automl.logger: 12-02 22:35:36] {1900} INFO - List of ML learners in AutoML Run: ['xgboost', 'lgbm', 'rf', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 12-02 22:35:36] {2218} INFO - iteration 0, current learner xgboost\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\azure-automl-webinar\\automl.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Leo/OneDrive/Programming/Python/azure/azure-automl-webinar/automl.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoML\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Leo/OneDrive/Programming/Python/azure/azure-automl-webinar/automl.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m automl \u001b[39m=\u001b[39m AutoML()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Leo/OneDrive/Programming/Python/azure/azure-automl-webinar/automl.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m automl\u001b[39m.\u001b[39;49mfit(X_train, y_train, task\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mregression\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\flaml\\automl\\automl.py:1928\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[1;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, preserve_checkpoint, early_stop, force_cancel, append_log, auto_augment, min_sample_size, use_ray, use_spark, free_mem_ratio, metric_constraints, custom_hp, time_col, cv_score_agg_func, skip_transform, mlflow_logging, fit_kwargs_by_estimator, **fit_kwargs)\u001b[0m\n\u001b[0;32m   1926\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_training_log \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1928\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_search()\n\u001b[0;32m   1929\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_best_estimator:\n\u001b[0;32m   1930\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mfit succeeded\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\flaml\\automl\\automl.py:2482\u001b[0m, in \u001b[0;36mAutoML._search\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2480\u001b[0m     state\u001b[39m.\u001b[39mbest_config \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39minit_config[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m state\u001b[39m.\u001b[39minit_config \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m   2481\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_ray \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_spark \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m-> 2482\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_search_sequential()\n\u001b[0;32m   2483\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2484\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_search_parallel()\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\flaml\\automl\\automl.py:2318\u001b[0m, in \u001b[0;36mAutoML._search_sequential\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2312\u001b[0m         search_state\u001b[39m.\u001b[39msearch_alg\u001b[39m.\u001b[39msearcher\u001b[39m.\u001b[39mset_search_properties(\n\u001b[0;32m   2313\u001b[0m             metric\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2314\u001b[0m             mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2315\u001b[0m             metric_target\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mbest_loss,\n\u001b[0;32m   2316\u001b[0m         )\n\u001b[0;32m   2317\u001b[0m start_run_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m-> 2318\u001b[0m analysis \u001b[39m=\u001b[39m tune\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m   2319\u001b[0m     search_state\u001b[39m.\u001b[39;49mtraining_function,\n\u001b[0;32m   2320\u001b[0m     search_alg\u001b[39m=\u001b[39;49msearch_state\u001b[39m.\u001b[39;49msearch_alg,\n\u001b[0;32m   2321\u001b[0m     time_budget_s\u001b[39m=\u001b[39;49mtime_budget_s,\n\u001b[0;32m   2322\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mmax\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose \u001b[39m-\u001b[39;49m \u001b[39m3\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[0;32m   2323\u001b[0m     use_ray\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   2324\u001b[0m     use_spark\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   2325\u001b[0m )\n\u001b[0;32m   2326\u001b[0m time_used \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_run_time\n\u001b[0;32m   2327\u001b[0m better \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\flaml\\tune\\tune.py:808\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_spark, use_incumbent_result_in_evaluation, log_file_name, lexico_objectives, force_cancel, n_concurrent_trials, **ray_args)\u001b[0m\n\u001b[0;32m    806\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[39mwith\u001b[39;00m PySparkOvertimeMonitor(time_start, time_budget_s, force_cancel):\n\u001b[1;32m--> 808\u001b[0m     result \u001b[39m=\u001b[39m evaluation_function(trial_to_run\u001b[39m.\u001b[39;49mconfig)\n\u001b[0;32m    809\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    810\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\flaml\\automl\\state.py:302\u001b[0m, in \u001b[0;36mAutoMLState._compute_with_config_base\u001b[1;34m(config_w_resource, state, estimator, is_report)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[39mdel\u001b[39;00m config[\u001b[39m\"\u001b[39m\u001b[39mFLAML_sample_size\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    288\u001b[0m budget \u001b[39m=\u001b[39m (\n\u001b[0;32m    289\u001b[0m     \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     \u001b[39mif\u001b[39;00m state\u001b[39m.\u001b[39mtime_budget \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[39melse\u001b[39;00m (state\u001b[39m.\u001b[39mtime_budget \u001b[39m-\u001b[39m state\u001b[39m.\u001b[39mtime_from_start) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m sample_size \u001b[39m/\u001b[39m state\u001b[39m.\u001b[39mdata_size[\u001b[39m0\u001b[39m]\n\u001b[0;32m    294\u001b[0m )\n\u001b[0;32m    296\u001b[0m (\n\u001b[0;32m    297\u001b[0m     trained_estimator,\n\u001b[0;32m    298\u001b[0m     val_loss,\n\u001b[0;32m    299\u001b[0m     metric_for_logging,\n\u001b[0;32m    300\u001b[0m     _,\n\u001b[0;32m    301\u001b[0m     pred_time,\n\u001b[1;32m--> 302\u001b[0m ) \u001b[39m=\u001b[39m compute_estimator(\n\u001b[0;32m    303\u001b[0m     sampled_X_train,\n\u001b[0;32m    304\u001b[0m     sampled_y_train,\n\u001b[0;32m    305\u001b[0m     state\u001b[39m.\u001b[39;49mX_val,\n\u001b[0;32m    306\u001b[0m     state\u001b[39m.\u001b[39;49my_val,\n\u001b[0;32m    307\u001b[0m     state\u001b[39m.\u001b[39;49mweight_val,\n\u001b[0;32m    308\u001b[0m     state\u001b[39m.\u001b[39;49mgroups_val,\n\u001b[0;32m    309\u001b[0m     state\u001b[39m.\u001b[39;49mtrain_time_limit \u001b[39mif\u001b[39;49;00m budget \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mmin\u001b[39;49m(budget, state\u001b[39m.\u001b[39;49mtrain_time_limit \u001b[39mor\u001b[39;49;00m np\u001b[39m.\u001b[39;49minf),\n\u001b[0;32m    310\u001b[0m     state\u001b[39m.\u001b[39;49mkf,\n\u001b[0;32m    311\u001b[0m     config,\n\u001b[0;32m    312\u001b[0m     state\u001b[39m.\u001b[39;49mtask,\n\u001b[0;32m    313\u001b[0m     estimator,\n\u001b[0;32m    314\u001b[0m     state\u001b[39m.\u001b[39;49meval_method,\n\u001b[0;32m    315\u001b[0m     state\u001b[39m.\u001b[39;49mmetric,\n\u001b[0;32m    316\u001b[0m     state\u001b[39m.\u001b[39;49mbest_loss,\n\u001b[0;32m    317\u001b[0m     state\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    318\u001b[0m     state\u001b[39m.\u001b[39;49mlearner_classes\u001b[39m.\u001b[39;49mget(estimator),\n\u001b[0;32m    319\u001b[0m     state\u001b[39m.\u001b[39;49mcv_score_agg_func,\n\u001b[0;32m    320\u001b[0m     state\u001b[39m.\u001b[39;49mlog_training_metric,\n\u001b[0;32m    321\u001b[0m     this_estimator_kwargs,\n\u001b[0;32m    322\u001b[0m     state\u001b[39m.\u001b[39;49mfree_mem_ratio,\n\u001b[0;32m    323\u001b[0m )\n\u001b[0;32m    324\u001b[0m \u001b[39mif\u001b[39;00m state\u001b[39m.\u001b[39mretrain_final \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m state\u001b[39m.\u001b[39mmodel_history:\n\u001b[0;32m    325\u001b[0m     trained_estimator\u001b[39m.\u001b[39mcleanup()\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\flaml\\automl\\ml.py:369\u001b[0m, in \u001b[0;36mcompute_estimator\u001b[1;34m(X_train, y_train, X_val, y_val, weight_val, groups_val, budget, kf, config_dic, task, estimator_name, eval_method, eval_metric, best_val_loss, n_jobs, estimator_class, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[0;32m    351\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[39m=\u001b[39m get_val_loss(\n\u001b[0;32m    352\u001b[0m         config_dic,\n\u001b[0;32m    353\u001b[0m         estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m         free_mem_ratio\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m    367\u001b[0m     )\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 369\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39;49mevaluate_model_CV(\n\u001b[0;32m    370\u001b[0m         config_dic,\n\u001b[0;32m    371\u001b[0m         estimator,\n\u001b[0;32m    372\u001b[0m         X_train,\n\u001b[0;32m    373\u001b[0m         y_train,\n\u001b[0;32m    374\u001b[0m         budget,\n\u001b[0;32m    375\u001b[0m         kf,\n\u001b[0;32m    376\u001b[0m         eval_metric,\n\u001b[0;32m    377\u001b[0m         best_val_loss,\n\u001b[0;32m    378\u001b[0m         cv_score_agg_func,\n\u001b[0;32m    379\u001b[0m         log_training_metric\u001b[39m=\u001b[39;49mlog_training_metric,\n\u001b[0;32m    380\u001b[0m         fit_kwargs\u001b[39m=\u001b[39;49mfit_kwargs,\n\u001b[0;32m    381\u001b[0m         free_mem_ratio\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m    382\u001b[0m     )\n\u001b[0;32m    384\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(estimator, TransformersEstimator):\n\u001b[0;32m    385\u001b[0m     \u001b[39mdel\u001b[39;00m fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m], fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39mX_val\u001b[39m\u001b[39m\"\u001b[39m], fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39my_val\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\flaml\\automl\\task\\generic_task.py:737\u001b[0m, in \u001b[0;36mGenericTask.evaluate_model_CV\u001b[1;34m(self, config, estimator, X_train_all, y_train_all, budget, kf, eval_metric, best_val_loss, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[0;32m    734\u001b[0m         groups_val \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    736\u001b[0m estimator\u001b[39m.\u001b[39mcleanup()\n\u001b[1;32m--> 737\u001b[0m val_loss_i, metric_i, train_time_i, pred_time_i \u001b[39m=\u001b[39m get_val_loss(\n\u001b[0;32m    738\u001b[0m     config,\n\u001b[0;32m    739\u001b[0m     estimator,\n\u001b[0;32m    740\u001b[0m     X_train,\n\u001b[0;32m    741\u001b[0m     y_train,\n\u001b[0;32m    742\u001b[0m     X_val,\n\u001b[0;32m    743\u001b[0m     y_val,\n\u001b[0;32m    744\u001b[0m     weight_val,\n\u001b[0;32m    745\u001b[0m     groups_val,\n\u001b[0;32m    746\u001b[0m     eval_metric,\n\u001b[0;32m    747\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    748\u001b[0m     labels,\n\u001b[0;32m    749\u001b[0m     budget_per_train,\n\u001b[0;32m    750\u001b[0m     log_training_metric\u001b[39m=\u001b[39;49mlog_training_metric,\n\u001b[0;32m    751\u001b[0m     fit_kwargs\u001b[39m=\u001b[39;49mfit_kwargs,\n\u001b[0;32m    752\u001b[0m     free_mem_ratio\u001b[39m=\u001b[39;49mfree_mem_ratio,\n\u001b[0;32m    753\u001b[0m )\n\u001b[0;32m    754\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(metric_i, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mintermediate_results\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m metric_i\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    755\u001b[0m     \u001b[39mdel\u001b[39;00m metric_i[\u001b[39m\"\u001b[39m\u001b[39mintermediate_results\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\flaml\\automl\\ml.py:494\u001b[0m, in \u001b[0;36mget_val_loss\u001b[1;34m(config, estimator, X_train, y_train, X_val, y_val, weight_val, groups_val, eval_metric, task, labels, budget, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[0;32m    489\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    490\u001b[0m \u001b[39m# if groups_val is not None:\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[39m#     fit_kwargs['groups_val'] = groups_val\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[39m#     fit_kwargs['X_val'] = X_val\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[39m#     fit_kwargs['y_val'] = y_val\u001b[39;00m\n\u001b[1;32m--> 494\u001b[0m estimator\u001b[39m.\u001b[39mfit(X_train, y_train, budget\u001b[39m=\u001b[39mbudget, free_mem_ratio\u001b[39m=\u001b[39mfree_mem_ratio, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    495\u001b[0m val_loss, metric_for_logging, pred_time, _ \u001b[39m=\u001b[39m _eval_estimator(\n\u001b[0;32m    496\u001b[0m     config,\n\u001b[0;32m    497\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    508\u001b[0m     fit_kwargs,\n\u001b[0;32m    509\u001b[0m )\n\u001b[0;32m    510\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mintermediate_results\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\flaml\\automl\\model.py:1653\u001b[0m, in \u001b[0;36mXGBoostSklearnEstimator.fit\u001b[1;34m(self, X_train, y_train, budget, free_mem_ratio, **kwargs)\u001b[0m\n\u001b[0;32m   1651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mtree_method\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpu_hist\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1652\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mgpu_per_trial\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1653\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X_train, y_train, budget, free_mem_ratio, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\flaml\\automl\\model.py:1405\u001b[0m, in \u001b[0;36mLGBMEstimator.fit\u001b[1;34m(self, X_train, y_train, budget, free_mem_ratio, **kwargs)\u001b[0m\n\u001b[0;32m   1403\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m   1404\u001b[0m         callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1405\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(\n\u001b[0;32m   1406\u001b[0m     X_train,\n\u001b[0;32m   1407\u001b[0m     y_train,\n\u001b[0;32m   1408\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[0;32m   1409\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   1410\u001b[0m )\n\u001b[0;32m   1411\u001b[0m \u001b[39mif\u001b[39;00m callbacks \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1412\u001b[0m     \u001b[39m# for xgboost>=1.6.0, pop callbacks to enable pickle\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m     callbacks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\flaml\\automl\\model.py:217\u001b[0m, in \u001b[0;36mBaseEstimator._fit\u001b[1;34m(self, X_train, y_train, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mif\u001b[39;00m logger\u001b[39m.\u001b[39mlevel \u001b[39m==\u001b[39m logging\u001b[39m.\u001b[39mDEBUG:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# xgboost 1.6 doesn't display all the params in the model str\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mflaml.automl.model - \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m fit started with params \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 217\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    218\u001b[0m \u001b[39mif\u001b[39;00m logger\u001b[39m.\u001b[39mlevel \u001b[39m==\u001b[39m logging\u001b[39m.\u001b[39mDEBUG:\n\u001b[0;32m    219\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mflaml.automl.model - \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m fit finished\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\xgboost\\sklearn.py:1086\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1075\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m (\n\u001b[0;32m   1078\u001b[0m     model,\n\u001b[0;32m   1079\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1085\u001b[0m )\n\u001b[1;32m-> 1086\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1087\u001b[0m     params,\n\u001b[0;32m   1088\u001b[0m     train_dmatrix,\n\u001b[0;32m   1089\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1090\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1091\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1092\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1093\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1094\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1095\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1096\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1097\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1098\u001b[0m )\n\u001b[0;32m   1100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\xgboost\\core.py:2046\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtrain, DMatrix):\n\u001b[0;32m   2045\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid training matrix: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(dtrain)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2046\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2048\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2049\u001b[0m     _check_call(\n\u001b[0;32m   2050\u001b[0m         _LIB\u001b[39m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2051\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, ctypes\u001b[39m.\u001b[39mc_int(iteration), dtrain\u001b[39m.\u001b[39mhandle\n\u001b[0;32m   2052\u001b[0m         )\n\u001b[0;32m   2053\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\xgboost\\core.py:2923\u001b[0m, in \u001b[0;36mBooster._assign_dmatrix_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   2922\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_assign_dmatrix_features\u001b[39m(\u001b[39mself\u001b[39m, data: DMatrix) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2923\u001b[0m     \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39;49mnum_row() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2924\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   2926\u001b[0m     fn \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mfeature_names\n",
      "File \u001b[1;32mc:\\Users\\Leo\\OneDrive\\Programming\\Python\\azure\\sdk-v2\\lib\\site-packages\\xgboost\\core.py:1216\u001b[0m, in \u001b[0;36mDMatrix.num_row\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get the number of rows in the DMatrix.\"\"\"\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m ret \u001b[39m=\u001b[39m c_bst_ulong()\n\u001b[1;32m-> 1216\u001b[0m _check_call(_LIB\u001b[39m.\u001b[39;49mXGDMatrixNumRow(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mbyref(ret)))\n\u001b[0;32m   1217\u001b[0m \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mvalue\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Azure SDK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: .\\config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient.from_config(credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python312\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import mltable\n",
    "\n",
    "paths = [\n",
    "    {\"file\": \"./data/train.csv\"}\n",
    "]\n",
    "\n",
    "train_table = mltable.from_delimited_files(paths)\n",
    "train_table.save('./data/mltable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!az ml compute create -f compute.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Instances need to have a unique name across the region.\n",
    "# Here we create a unique name with current datetime\n",
    "from azure.ai.ml.entities import ComputeInstance, AmlCompute\n",
    "import datetime\n",
    "\n",
    "compute_name = \"automl-webinar\"\n",
    "ci_basic = ComputeInstance(\n",
    "    name=compute_name, \n",
    "    size=\"STANDARD_D2AS_V4\", # 2 cores, 8GB RAM, 16GB Storage\n",
    "    idle_time_before_shutdown_minutes=\"30\"\n",
    ")\n",
    "ml_client.begin_create_or_update(ci_basic).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import automl, Input\n",
    "\n",
    "# note that this is a code snippet -- you might have to modify the variable values to run it successfully\n",
    "\n",
    "# make an Input object for the training data\n",
    "training_data_input = Input(\n",
    "    type=AssetTypes.MLTABLE, path=\"./data/training-mltable-folder\"\n",
    ")\n",
    "\n",
    "# configure the classification job\n",
    "classification_job = automl.regression(\n",
    "    compute=compute_name,\n",
    "    experiment_name=\"automl-webinar-blueberry-prediction\",\n",
    "    training_data=training_data_input,\n",
    "    target_column_name=\"yield\",\n",
    "    primary_metric=\"mae\",\n",
    "    n_cross_validations=5,\n",
    "    enable_model_explainability=True,\n",
    "    tags={\"my_custom_tag\": \"My custom value\"}\n",
    ")\n",
    "\n",
    "# Limits are all optional\n",
    "classification_job.set_limits(\n",
    "    timeout_minutes=600, \n",
    "    trial_timeout_minutes=20, \n",
    "    max_trials=5,\n",
    "    enable_early_termination=True,\n",
    ")\n",
    "\n",
    "# Training properties are optional\n",
    "classification_job.set_training(\n",
    "    blocked_training_algorithms=[\"logistic_regression\"], \n",
    "    enable_onnx_compatible_models=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatives to Azure AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdk-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
